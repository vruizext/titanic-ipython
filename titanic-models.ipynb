{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##load required libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# For .read_csv, always use header=0 when you know row 0 is the header row\n",
    "trainDf = pd.read_csv('data/train.csv', header=0)\n",
    "testDf = pd.read_csv('data/test.csv', header=0)\n",
    "\n",
    "#keep passengerIds to split the df at the end of preprocessing\n",
    "trainIds = trainDf.PassengerId\n",
    "testIds = testDf.PassengerId\n",
    "\n",
    "df = pd.concat([trainDf, testDf])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#create a new column \"Gender\",  using map function\n",
    "df['Gender'] = df['Sex'].map( {'female': 0, 'male': 1} ).astype(int)\n",
    "\n",
    "#how big was the family?\n",
    "df['FamilySize'] = df['SibSp'] + df['Parch'] + 1\n",
    "\n",
    "#how many passengrs travelling together with same ticket?\n",
    "tickets = df['Ticket'].value_counts()\n",
    "tickets = pd.DataFrame({'Ticket': tickets.index, 'Ticket_N': tickets.values})\n",
    "#join Ticket_N column with DF\n",
    "df = pd.merge(df, tickets, how='left')\n",
    "#impute missing value to the median fare price of 3rd class\n",
    "df.loc[df.Fare.isnull(), 'Fare'] = df.groupby(\"Pclass\")[\"Fare\"].median()[3]\n",
    "#fare per person, divide fare by the number of persons travelling with the ticket\n",
    "df['Fare_N'] = df.Fare / df.Ticket_N"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#extract the title from the name field\n",
    "df['Title'] = df.Name.apply(lambda x: re.split('[,.]\\s?', x)[1])\n",
    "\n",
    "#map rare titles to the most common equivalents\n",
    "df.loc[df.Title.isin(['Lady', 'the Countess']), 'Title'] = \"Mrs\"\n",
    "df.loc[df.Title.isin(['Mme', 'Mlle']), 'Title'] = \"Miss\"\n",
    "df.loc[df.Title == 'Ms', 'Title'] = \"Mrs\"\n",
    "df.loc[df.Title.isin(['Capt', 'Major', 'Col', 'Rev', 'Jonkheer', 'Sir']), 'Title'] = \"Sir\"  \n",
    "df.loc[df.Title == 'Don', 'Title'] = \"Mr\"\n",
    "df.loc[df.Title == 'Dona', 'Title'] = \"Mrs\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#create a copy of the \"Age\" field to impute missing values, leave original field as it'S\n",
    "df['Age_'] = df['Age']\n",
    "#fill na's with the median values for each \"Title\"-\"Pclass\" group\n",
    "df['Age_'] = df.groupby([\"Pclass\", \"Title\"]).Age.transform(lambda x: x.fillna(x.median()))\n",
    "df['Age_isNull'] = pd.isnull(df.Age).astype(int)\n",
    "\n",
    "#engineered feature\n",
    "df['Age_x_Pclass'] = df['Age_'] * df.Pclass.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#extract surname in a separate field\n",
    "df['Surname'] = df.Name.apply(lambda x: re.split('[,.]\\s?', x)[0])\n",
    "df['FamilyId'] = df.Surname + \"-\" + df.FamilySize.astype(str)\n",
    "df[['FamilySize', 'FamilyId']].head(25)\n",
    "#discard small families (fewer than 2 people), there are way too many, and had higher chance to survive\n",
    "df.loc[df.FamilySize < 3, 'FamilyId'] = 'X-X'\n",
    "families = df.FamilyId.value_counts()\n",
    "families = pd.DataFrame({'FamilyId': families.index, 'Size': families.values})\n",
    "#families.head()\n",
    "wrongCounts = families.FamilyId[families.Size < 3]\n",
    "df.loc[df.FamilyId.isin(wrongCounts), 'FamilyId'] = 'X-X'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#childs and women had priority, when taking the boats, add an indicator for this\n",
    "df['Priority'] = 0\n",
    "df.loc[df.Age < 15, 'Priority'] = 1\n",
    "df.loc[df.Title == \"Master\", 'Priority'] = 1 #master was used for kids until 12-15 years\n",
    "df.loc[df.Sex == \"female\", 'Priority'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#we get the firt character of the ticket, it can be used to cluster tickets/passengers in groups\n",
    "df['TicketType'] = df.Ticket.apply(lambda s: s.translate(None, \"[][!#$%()*,.:;<=>@^_`|~.{} ]\")[0])\n",
    "df.TicketType.value_counts()\n",
    "\n",
    "#impute missing values to the most common case\n",
    "df.loc[df.Embarked.isnull(), 'Embarked'] = \"S\"\n",
    "df['Port'] = df['Embarked'].map( {'S': 0, 'C': 1, 'Q': 2} ).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#map string variables to integers... scikit-learn needs numeric data\n",
    "df['Ticket_'] = pd.factorize(df.TicketType)[0]\n",
    "df['FamilyId_'] = pd.factorize(df.FamilyId)[0]\n",
    "df['Title_'] = pd.factorize(df.Title)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 1309 entries, 0 to 1308\n",
      "Data columns (total 28 columns):\n",
      "Age             1046 non-null float64\n",
      "Cabin           295 non-null object\n",
      "Embarked        1309 non-null object\n",
      "Fare            1309 non-null float64\n",
      "Name            1309 non-null object\n",
      "Parch           1309 non-null int64\n",
      "PassengerId     1309 non-null int64\n",
      "Pclass          1309 non-null int64\n",
      "Sex             1309 non-null object\n",
      "SibSp           1309 non-null int64\n",
      "Survived        891 non-null float64\n",
      "Ticket          1309 non-null object\n",
      "Gender          1309 non-null int64\n",
      "FamilySize      1309 non-null int64\n",
      "Ticket_N        1309 non-null int64\n",
      "Fare_N          1309 non-null float64\n",
      "Title           1309 non-null object\n",
      "Age_            1309 non-null float64\n",
      "Age_isNull      1309 non-null int64\n",
      "Age_x_Pclass    1309 non-null float64\n",
      "Surname         1309 non-null object\n",
      "FamilyId        1309 non-null object\n",
      "Priority        1309 non-null int64\n",
      "TicketType      1309 non-null object\n",
      "Port            1309 non-null int64\n",
      "Ticket_         1309 non-null int64\n",
      "FamilyId_       1309 non-null int64\n",
      "Title_          1309 non-null int64\n",
      "dtypes: float64(6), int64(13), object(9)\n",
      "memory usage: 296.6+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#split again df in train and test\n",
    "trainDf = df[df.PassengerId.isin(trainIds)]\n",
    "testDf = df[df.PassengerId.isin(testIds)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(390, 2)\n",
      "(390, 28)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Name</th>\n",
       "      <th>Parch</th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>...</th>\n",
       "      <th>Age_x_Pclass</th>\n",
       "      <th>Surname</th>\n",
       "      <th>FamilyId</th>\n",
       "      <th>Priority</th>\n",
       "      <th>TicketType</th>\n",
       "      <th>Port</th>\n",
       "      <th>Ticket_</th>\n",
       "      <th>FamilyId_</th>\n",
       "      <th>Title_</th>\n",
       "      <th>Survived</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td> 47</td>\n",
       "      <td> NaN</td>\n",
       "      <td> S</td>\n",
       "      <td>  7.0000</td>\n",
       "      <td>             Wilkes, Mrs. James (Ellen Needs)</td>\n",
       "      <td> 0</td>\n",
       "      <td> 893</td>\n",
       "      <td> 3</td>\n",
       "      <td> female</td>\n",
       "      <td> 1</td>\n",
       "      <td>...</td>\n",
       "      <td> 141</td>\n",
       "      <td>   Wilkes</td>\n",
       "      <td> X-X</td>\n",
       "      <td> 1</td>\n",
       "      <td> 3</td>\n",
       "      <td> 0</td>\n",
       "      <td> 4</td>\n",
       "      <td> 0</td>\n",
       "      <td> 1</td>\n",
       "      <td> 1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td> 62</td>\n",
       "      <td> NaN</td>\n",
       "      <td> Q</td>\n",
       "      <td>  9.6875</td>\n",
       "      <td>                    Myles, Mr. Thomas Francis</td>\n",
       "      <td> 0</td>\n",
       "      <td> 894</td>\n",
       "      <td> 2</td>\n",
       "      <td>   male</td>\n",
       "      <td> 0</td>\n",
       "      <td>...</td>\n",
       "      <td> 124</td>\n",
       "      <td>    Myles</td>\n",
       "      <td> X-X</td>\n",
       "      <td> 0</td>\n",
       "      <td> 2</td>\n",
       "      <td> 2</td>\n",
       "      <td> 5</td>\n",
       "      <td> 0</td>\n",
       "      <td> 0</td>\n",
       "      <td> 0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td> 27</td>\n",
       "      <td> NaN</td>\n",
       "      <td> S</td>\n",
       "      <td>  8.6625</td>\n",
       "      <td>                             Wirz, Mr. Albert</td>\n",
       "      <td> 0</td>\n",
       "      <td> 895</td>\n",
       "      <td> 3</td>\n",
       "      <td>   male</td>\n",
       "      <td> 0</td>\n",
       "      <td>...</td>\n",
       "      <td>  81</td>\n",
       "      <td>     Wirz</td>\n",
       "      <td> X-X</td>\n",
       "      <td> 0</td>\n",
       "      <td> 3</td>\n",
       "      <td> 0</td>\n",
       "      <td> 4</td>\n",
       "      <td> 0</td>\n",
       "      <td> 0</td>\n",
       "      <td> 0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td> 22</td>\n",
       "      <td> NaN</td>\n",
       "      <td> S</td>\n",
       "      <td> 12.2875</td>\n",
       "      <td> Hirvonen, Mrs. Alexander (Helga E Lindqvist)</td>\n",
       "      <td> 1</td>\n",
       "      <td> 896</td>\n",
       "      <td> 3</td>\n",
       "      <td> female</td>\n",
       "      <td> 1</td>\n",
       "      <td>...</td>\n",
       "      <td>  66</td>\n",
       "      <td> Hirvonen</td>\n",
       "      <td> X-X</td>\n",
       "      <td> 1</td>\n",
       "      <td> 3</td>\n",
       "      <td> 0</td>\n",
       "      <td> 4</td>\n",
       "      <td> 0</td>\n",
       "      <td> 1</td>\n",
       "      <td> 1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td> 14</td>\n",
       "      <td> NaN</td>\n",
       "      <td> S</td>\n",
       "      <td>  9.2250</td>\n",
       "      <td>                   Svensson, Mr. Johan Cervin</td>\n",
       "      <td> 0</td>\n",
       "      <td> 897</td>\n",
       "      <td> 3</td>\n",
       "      <td>   male</td>\n",
       "      <td> 0</td>\n",
       "      <td>...</td>\n",
       "      <td>  42</td>\n",
       "      <td> Svensson</td>\n",
       "      <td> X-X</td>\n",
       "      <td> 1</td>\n",
       "      <td> 7</td>\n",
       "      <td> 0</td>\n",
       "      <td> 7</td>\n",
       "      <td> 0</td>\n",
       "      <td> 0</td>\n",
       "      <td> 1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Age Cabin Embarked     Fare                                          Name  \\\n",
       "0   47   NaN        S   7.0000              Wilkes, Mrs. James (Ellen Needs)   \n",
       "1   62   NaN        Q   9.6875                     Myles, Mr. Thomas Francis   \n",
       "2   27   NaN        S   8.6625                              Wirz, Mr. Albert   \n",
       "3   22   NaN        S  12.2875  Hirvonen, Mrs. Alexander (Helga E Lindqvist)   \n",
       "4   14   NaN        S   9.2250                    Svensson, Mr. Johan Cervin   \n",
       "\n",
       "   Parch  PassengerId  Pclass     Sex  SibSp   ...    Age_x_Pclass   Surname  \\\n",
       "0      0          893       3  female      1   ...             141    Wilkes   \n",
       "1      0          894       2    male      0   ...             124     Myles   \n",
       "2      0          895       3    male      0   ...              81      Wirz   \n",
       "3      1          896       3  female      1   ...              66  Hirvonen   \n",
       "4      0          897       3    male      0   ...              42  Svensson   \n",
       "\n",
       "   FamilyId  Priority  TicketType Port  Ticket_  FamilyId_  Title_ Survived  \n",
       "0       X-X         1           3    0        4          0       1        1  \n",
       "1       X-X         0           2    2        5          0       0        0  \n",
       "2       X-X         0           3    0        4          0       0        0  \n",
       "3       X-X         1           3    0        4          0       1        1  \n",
       "4       X-X         1           7    0        7          0       0        1  \n",
       "\n",
       "[5 rows x 28 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#extract survived values for test dataset\n",
    "survTestDf = pd.read_csv(\"data/test-full.csv\", header=0)\n",
    "print survTestDf.shape\n",
    "#survTestDf = survTestDf[[\"PassengerId\", \"Survived\"]]\n",
    "testDf = testDf.drop('Survived', 1)\n",
    "testDf2 = pd.merge(testDf, survTestDf, on=\"PassengerId\", how='right')\n",
    "print testDf2.shape\n",
    "testDf2.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.cross_validation import cross_val_score, LeaveOneOut\n",
    "from scipy.stats import sem\n",
    "\n",
    "def loo_cv(X_train,y_train,clf):\n",
    "    # Perform Leave-One-Out cross validation\n",
    "    # We are preforming 1313 classifications!\n",
    "    loo = LeaveOneOut(X_train[:].shape[0])\n",
    "    scores=np.zeros(X_train[:].shape[0])\n",
    "    for train_index,test_index in loo:\n",
    "        X_train_cv, X_test_cv= X_train[train_index], X_train[test_index]\n",
    "        y_train_cv, y_test_cv= y_train[train_index], y_train[test_index]\n",
    "        clf = clf.fit(X_train_cv,y_train_cv)\n",
    "        y_pred=clf.predict(X_test_cv)\n",
    "        scores[test_index]=metrics.accuracy_score(y_test_cv.astype(int), y_pred.astype(int))\n",
    "    print (\"Mean score: {0:.3f} (+/-{1:.3f})\").format(np.mean(scores), sem(scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cross val score -> 0.832772166105)\n",
      "score on test set -> 0.776923076923)\n"
     ]
    }
   ],
   "source": [
    "# Import the random forest package\n",
    "from sklearn.cross_validation import cross_val_score, LeaveOneOut\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import cross_validation\n",
    "\n",
    "#kf = cross_validation.KFold(len(trainDf['Survived']), n_folds=2)\n",
    "\n",
    "# Create the random forest object which will include all the parameters\n",
    "# for the fit\n",
    "forest = RandomForestClassifier(n_estimators = 500, max_features = 3, max_depth = 20, \n",
    "                                criterion=\"gini\", min_samples_leaf = 3,  min_samples_split=6,\n",
    "                                 oob_score = True, n_jobs=2, random_state=1234) # max_depth = 6-7\n",
    "\n",
    "#predictors = ['Pclass', 'Gender', 'Age_', 'Fare_N', 'Priority', 'FamilySize', 'SibSp', 'Parch', 'Port', \n",
    "#              'FamilyId_', 'Ticket_', 'Title_', 'Age_isNull', 'Age_x_Pclass']\n",
    "\n",
    "predictors = ['Pclass', 'Gender', 'Age_','FamilySize', 'Title_', 'Ticket_', 'Fare_N', 'Priority', 'Ticket_N', 'FamilyId_']\n",
    "\n",
    "# Fit the training data to the Survived labels and create the decision trees\n",
    "model_rf = forest.fit(trainDf[predictors],trainDf['Survived'])\n",
    "rf_score = cross_val_score(forest, trainDf[predictors], trainDf['Survived'], n_jobs=-1).mean()\n",
    "print(\"cross val score -> {0})\".format(rf_score))\n",
    "\n",
    "\n",
    "\n",
    "#loo_cv(trainDf[predictors],trainDf['Survived'], model_rf)\n",
    "\n",
    "# Take the same decision trees and run it on the test data\n",
    "output = model_rf.predict(testDf2[predictors])\n",
    "#print forest.score(trainDf[predictors],trainDf['Survived'])\n",
    "print(\"score on test set -> {0})\".format(forest.score(testDf2[predictors],testDf2['Survived'])))\n",
    "output = model_rf.predict(testDf[predictors])\n",
    "outDf = pd.DataFrame({'PassengerId': testDf.PassengerId, 'Survived': output.astype(int)})\n",
    "outDf.to_csv('data/rf-test.csv', index = False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score on test set -> 0.753846153846)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "bdt = AdaBoostClassifier(forest, algorithm=\"SAMME\", n_estimators=100)\n",
    "\n",
    "model_bdt = bdt.fit(trainDf[predictors],trainDf['Survived'])\n",
    "out = model_bdt.predict(testDf2[predictors])\n",
    "print(\"score on test set -> {0})\".format(model_bdt.score(testDf2[predictors],testDf2['Survived'])))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cross val score -> 0.83950617284)\n",
      " score on train set -> 0.937149270483)\n",
      " score on test set -> 0.774358974359)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.cross_validation import cross_val_score\n",
    "\n",
    "predictors = ['Pclass', 'Gender', 'Age_', 'FamilySize', 'FamilyId_','Title_', 'Ticket_', 'Fare_N', 'Priority', 'Ticket_N']\n",
    "#'Fare_N', 'Priority', 'FamilySize', 'SibSp', 'Parch','Port','FamilyId_', 'Ticket_', 'Title_', 'Age_x_Pclass'\n",
    "et = ExtraTreesClassifier(n_estimators=480, criterion=\"gini\", max_features = 3, max_depth=18, min_samples_split=6, random_state=1234)\n",
    "\n",
    "labels = trainDf[\"Survived\"].values\n",
    "features = trainDf[predictors].values\n",
    " \n",
    "et_score = cross_val_score(et, features, labels, n_jobs=-1).mean()\n",
    " \n",
    "print(\"cross val score -> {0})\".format(et_score))\n",
    "\n",
    "model = et.fit(trainDf[predictors],trainDf['Survived'])\n",
    "output = model.predict(testDf2[predictors])\n",
    "print(\"score on train set -> {0})\".format(et.score(trainDf[predictors],trainDf['Survived'])))\n",
    "print(\"score on test set -> {0})\".format(et.score(testDf2[predictors],testDf2['Survived'])))\n",
    "\n",
    "out = model.predict(testDf[predictors])\n",
    "outDf = pd.DataFrame({'PassengerId': testDf.PassengerId, 'Survived': out.astype(int)})\n",
    "outDf.to_csv('data/et-test.csv', index = False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score on test set -> 0.766666666667)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "predictors = ['Pclass', 'Gender', 'Age_', 'FamilySize', 'FamilyId_','Title_', \n",
    "              'Ticket_', 'Fare_N', 'Priority', 'Ticket_N']\n",
    "\n",
    "gbm = GradientBoostingClassifier(n_estimators=600, learning_rate=0.5, max_depth=1, random_state=1234)\n",
    "model_gbm = gbm.fit(trainDf[predictors],trainDf['Survived'])\n",
    "\n",
    "print(\"score on test set -> {0})\".format(model_gbm.score(testDf2[predictors],testDf2['Survived'])))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score on test set -> 0.748717948718)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "predictors = ['Pclass', 'Gender', 'Age_', 'FamilySize', 'FamilyId_','Title_', \n",
    "              'Ticket_', 'Fare_N', 'Priority', 'Ticket_N']\n",
    "nb = GaussianNB()\n",
    "model_nb = nb.fit(trainDf[predictors],trainDf['Survived'])\n",
    "\n",
    "print(\"score on test set -> {0})\".format(model_nb.score(testDf2[predictors],testDf2['Survived'])))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score on test set -> 0.730769230769)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "knn = KNeighborsClassifier(n_neighbors=20, algorithm = 'kd_tree', p = 1, leaf_size = 50)\n",
    "model_knn = knn.fit(trainDf[predictors],trainDf['Survived'])\n",
    "print(\"score on test set -> {0})\".format(model_knn.score(testDf2[predictors],testDf2['Survived'])))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
